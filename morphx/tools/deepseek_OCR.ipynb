{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YMTotZsATnF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdz7hvTNGbqB"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "os.makedirs(\"pdf_pages\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnjti8XJAsHO"
      },
      "outputs": [],
      "source": [
        "model_name = 'deepseek-ai/DeepSeek-OCR'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIeyYQ0dAyGs"
      },
      "outputs": [],
      "source": [
        "quantconfig = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN0gfKv5A5eG",
        "outputId": "4c0d6fc5-cc00-453c-8247-1ec758f7b434"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z7uQOfBcA-39",
        "outputId": "00d9b9ed-2818-4090-9012-dff5f47e971a"
      },
      "outputs": [],
      "source": [
        "model = AutoModel.from_pretrained(\n",
        "    model_name, trust_remote_code=True,\n",
        "    use_safetensors=True, device_map=\"auto\",\n",
        "    quantization_config=quantconfig, torch_dtype=torch.float, do_sample=False, temperature=None,\n",
        ")\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def clear_output_dir(path):\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['original_a9bdc0e3-826c-4e33-b257-7243270f58a9_PXL_20251223_115013128.jpg']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"<image>\\nConvert the document to markdown. \"\n",
        "path = \"/home/daniel/Documents/Repositorios/morphx/convert\"\n",
        "output_path = f'/home/daniel/Documents/Repositorios/morphx/morphx/tools/outputs'\n",
        "dir_list = os.listdir(path)\n",
        "dir_list.sort()\n",
        "dir_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start File: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "chmod. → o+r. arquivo\n",
            "\n",
            "o → otros\n",
            "+ → archivo\n",
            "r → lectura\n",
            "\n",
            "chmod. → o-u. arquivo. → otros. guitar. escritura\n",
            "    → arquivo, grupo y otros.\n",
            "chmod. → ugo+x. arquivo → archivo. ejecución...\n",
            "\n",
            "→ guia no hh. inicia una nueva sesión de shell.\n",
            "→ con chown. cambiando el propietario de\n",
            "    un director. Sue. Solo. lo puedes hacer con\n",
            "    sudo. p.ej.\n",
            "    → sudo chown user. doc.txt.\n",
            "==================================================\n",
            "image size:  (3468, 4624)\n",
            "valid image tokens:  792\n",
            "output texts tokens (valid):  127\n",
            "compression ratio:  0.16\n",
            "==================================================\n",
            "===============save results:===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End File: 0\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i, file in enumerate(dir_list):\n",
        "    print(f\"Start File: {i}\")\n",
        "    clear_output_dir(output_path)\n",
        "    model.infer(tokenizer, prompt=prompt, image_file=path + \"/\" + file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)\n",
        "    print(f\"End File: {i}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoiiJGGC6CgF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "morphx",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
